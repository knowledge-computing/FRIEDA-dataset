# FRIEDA: Benchmarking Multi-Step Cartographic Reasoning in Vision-Language Models

## About
### FRIEDA


<!-- ## Quick Start

# By default, you will use the remote evaluation API to execute the output samples.
pip install bigcodebench --upgrade

# You are suggested to use `flash-attn` for generating code samples.
pip install packaging ninja
pip install flash-attn --no-build-isolation
# Note: if you have installation problem, consider using pre-built
# wheels from https://github.com/Dao-AILab/flash-attention/releases -->

## Evaluation
<!-- 
## Usage

You can run the script with the following flags:  

### Required Flags

- `--model`  
  Name of the model to run (e.g., `gemini-2.5-pro`, `llava-hf/llava-onevision-qwen2-72b-ov-hf`).  
  *By default, this is set to the largest model in each family.*  

- `--questions`  
  Path to the JSON file containing the questions.  

- `--images`  
  Path to the directory containing the associated images.  

- `--distractor`  
  Whether to include contextual (distractor) images.  
  *(Note: this flag name will be updated in the future.)*  

### Open-Source Modelâ€“Only Flags
These flags apply only when running open-source models:  

- `--flash`  
  Enable Flash Attention for faster inference if supported.  

- `--batch_size`  
  Batch size for processing inputs.   -->